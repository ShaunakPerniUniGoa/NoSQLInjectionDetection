{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from dateutil import parser\n",
    "import json\n",
    "import ipaddress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignoreList = ['.length ']\n",
    "matchPatterns = []\n",
    "def tokenize_filter(filter_dict):\n",
    "    tokens = []\n",
    "    if filter_dict is not None:\n",
    "        filter_str = json.dumps(filter_dict)\n",
    "        tokens = re.findall(r\"\\[\\w']+|\\[.,!?;\\]\", filter_str)\n",
    "    return tokens\n",
    "\n",
    "def replace_alpha_words(text):\n",
    "    if text is None:\n",
    "        return(\"\")\n",
    "    else:\n",
    "        regex = r\"^(?!\\$)\\w+\"\n",
    "        return re.sub(r\"'[\\w ]+'\", '\\'name\\'', text)\n",
    "\n",
    "def replace_this_var(text):\n",
    "    matched = (re.findall(r\"\\.[\\w]+\",text))\n",
    "    #matchPatterns.append(matched)\n",
    "    for matches in matched:\n",
    "        if str(matches) != '.length':\n",
    "            text = re.sub(matches,\".name\",text)\n",
    "        else:\n",
    "            matchPatterns.append(matches)\n",
    "    return text\n",
    "\n",
    "def replace_this_var_condi(text):\n",
    "    regex = r\"^(?!\\$)\\w+\"\n",
    "    return re.sub(r\"\\.[\\w]+[\\.]\",\".name.\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'user': '{}', 'password': '{}'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'username': {'$regex': '^{}'}}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'username': {'$ne': '{}'}}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'username': {'$gt': '{}'}}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'user': 'hacker', 'password': {'$ne': ''}}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text  label\n",
       "0             {'user': '{}', 'password': '{}'}      0\n",
       "1              {'username': {'$regex': '^{}'}}      1\n",
       "2                  {'username': {'$ne': '{}'}}      1\n",
       "3                  {'username': {'$gt': '{}'}}      1\n",
       "4  {'user': 'hacker', 'password': {'$ne': ''}}      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelData = pd.read_json(\"../No-SQL_Gen/No-SqlDataset.json\")\n",
    "labelData['text'] = labelData['text'].apply(lambda x: x.replace('\"', \"'\") if isinstance(x, str) else x)\n",
    "labelData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    176371\n",
       "1    112781\n",
       "2     71093\n",
       "3     81173\n",
       "4    141175\n",
       "Name: cpuNanos, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logData = pd.read_json('../Dataset/queryLogs.json')\n",
    "logData.head()\n",
    "logData['t'] = logData['t'].apply(lambda x: parser.parse(x['$date']).timestamp())\n",
    "attr_cols = ['type', 'ns', 'command', 'planSummary', 'planningTimeMicros', 'keysExamined', 'docsExamined', 'nBatches', 'cursorExhausted', 'numYields', 'nreturned', 'queryFramework', 'reslen', 'locks', 'storage', 'cpuNanos', 'remote', 'protocol', 'durationMillis']\n",
    "for col in attr_cols:\n",
    "    logData[col] = logData['attr'].apply(lambda x: x.get(col, None))\n",
    "logData['FindCollectionTarget'] = logData['command'].apply(lambda x: x.get('find', None) if isinstance(x, dict) else \"None\")\n",
    "logData['filter'] = logData['command'].apply(lambda x: x.get('filter', None) if isinstance(x, dict) else None)\n",
    "logData['tokenized_filter'] = logData['filter'].apply(lambda x: tokenize_filter(str(x)) if x is not None else None)\n",
    "logData['docUUID'] = logData['command'].apply(lambda x: x.get('lsid', {}).get('id', {}).get('$uuid', None) if isinstance(x, dict) else None)\n",
    "logData['db'] = logData['command'].apply(lambda x: x.get('$db', None) if isinstance(x, dict) else None)\n",
    "logData['db'] = logData['command'].apply(lambda x: x.get('$db', None) if isinstance(x, dict) else None)\n",
    "logData['filter_str'] = logData['filter'].apply(lambda x: str(x) if x is not None else None)\n",
    "logData['returnDataSize'] = logData['command'].apply(lambda x: x.get('nreturned', None) if isinstance(x, dict) else None)\n",
    "#nreturned\n",
    "logData['cpuNanos'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelData = pd.read_json(\"../No-SQL_Gen/No-SqlDataset.json\")\n",
    "labelData['text'] = labelData['text'].apply(lambda x: x.replace('\"', \"'\") if isinstance(x, str) else x)\n",
    "labelData.head()\n",
    "merged_df = pd.merge(logData[['t','filter_str','remote','FindCollectionTarget','db','docUUID', 'nreturned', 'cpuNanos', 'planningTimeMicros']], labelData[['text', 'label']], how='left', left_on='filter_str', right_on='text')\n",
    "merged_df = merged_df.drop('text',axis=1)\n",
    "merged_df['FindCollectionTargetdeNamed'] = merged_df['FindCollectionTarget'].apply(replace_alpha_words)\n",
    "merged_df['filter_str'] = merged_df['filter_str'].apply(lambda x: x.replace('\"', \"'\") if isinstance(x, str) else x)\n",
    "merged_df['filter_str'] = merged_df['filter_str'].apply(lambda x : str(x))\n",
    "merged_df['queryLength'] = merged_df['filter_str'].apply(lambda x: len(str(x)))\n",
    "merged_df['whereDetected'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"\\$where\", x)) else 0)\n",
    "merged_df['regexDetected'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"\\$regex\", x)) else 0)\n",
    "merged_df['emptyFilter'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"^\\{\\}$\", x)) else 0)\n",
    "merged_df['nullArgument'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"\\{\\}'\", x)) else 0)\n",
    "merged_df['logicOperator'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"[=><]+\", x)) else 0)\n",
    "merged_df['denamed'] = merged_df['filter_str'].apply(replace_alpha_words)\n",
    "merged_df['denamed'] = merged_df['denamed'].apply(replace_this_var)\n",
    "merged_df['denamedDb'] = merged_df['db'].apply(replace_alpha_words)\n",
    "merged_df['ipHash'] = merged_df['remote'].apply(lambda ip: hash(int(ipaddress.IPv4Address(ip.split(':')[0]))))\n",
    "merged_df['port'] = merged_df['remote'].apply(lambda ip: ip.split(':')[1])\n",
    "merged_df = merged_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              t                        filter_str  \\\n",
      "0  1.712243e+09  {'user': '{}', 'password': '{}'}   \n",
      "1  1.712243e+09  {'user': '{}', 'password': '{}'}   \n",
      "2  1.712243e+09   {'username': {'$regex': '^{}'}}   \n",
      "3  1.712243e+09   {'username': {'$regex': '^{}'}}   \n",
      "4  1.712243e+09       {'username': {'$ne': '{}'}}   \n",
      "\n",
      "                                docUUID                       denamed  \\\n",
      "0  e5e23d7e-5367-4829-a104-ca369c49d4dc  {'name': '{}', 'name': '{}'}   \n",
      "1  e5e23d7e-5367-4829-a104-ca369c49d4dc  {'name': '{}', 'name': '{}'}   \n",
      "2  e5e23d7e-5367-4829-a104-ca369c49d4dc   {'name': {'$regex': '^{}'}}   \n",
      "3  e5e23d7e-5367-4829-a104-ca369c49d4dc   {'name': {'$regex': '^{}'}}   \n",
      "4  e5e23d7e-5367-4829-a104-ca369c49d4dc       {'name': {'$ne': '{}'}}   \n",
      "\n",
      "  FindCollectionTarget FindCollectionTargetdeNamed      ipHash   port  \\\n",
      "0      test_collection             test_collection  2130706433  47038   \n",
      "1      test_collection             test_collection  2130706433  47038   \n",
      "2      test_collection             test_collection  2130706433  47038   \n",
      "3      test_collection             test_collection  2130706433  47038   \n",
      "4      test_collection             test_collection  2130706433  47038   \n",
      "\n",
      "   whereDetected  regexDetected  emptyFilter  nullArgument  logicOperator  \\\n",
      "0              0              0            0             1              0   \n",
      "1              0              0            0             1              0   \n",
      "2              0              1            0             1              0   \n",
      "3              0              1            0             1              0   \n",
      "4              0              0            0             1              0   \n",
      "\n",
      "              db      denamedDb  nreturned  cpuNanos  label  \\\n",
      "0  test_database  test_database        0.0    176371    0.0   \n",
      "1  test_database  test_database        0.0    176371    0.0   \n",
      "2  test_database  test_database        0.0    112781    1.0   \n",
      "3  test_database  test_database        0.0    112781    1.0   \n",
      "4  test_database  test_database        0.0     71093    1.0   \n",
      "\n",
      "   planningTimeMicros  \n",
      "0                83.0  \n",
      "1                83.0  \n",
      "2                71.0  \n",
      "3                71.0  \n",
      "4                42.0  \n",
      "Shape of the DataFrame: (224, 19)\n",
      "\n",
      "Data Types:\n",
      "t                              float64\n",
      "filter_str                      object\n",
      "docUUID                         object\n",
      "denamed                         object\n",
      "FindCollectionTarget            object\n",
      "FindCollectionTargetdeNamed     object\n",
      "ipHash                           int64\n",
      "port                            object\n",
      "whereDetected                    int64\n",
      "regexDetected                    int64\n",
      "emptyFilter                      int64\n",
      "nullArgument                     int64\n",
      "logicOperator                    int64\n",
      "db                              object\n",
      "denamedDb                       object\n",
      "nreturned                      float64\n",
      "cpuNanos                         int64\n",
      "label                          float64\n",
      "planningTimeMicros             float64\n",
      "dtype: object\n",
      "\n",
      "Descriptive Statistics:\n",
      "                  t        ipHash  whereDetected  regexDetected  emptyFilter  \\\n",
      "count  2.240000e+02  2.240000e+02     224.000000     224.000000   224.000000   \n",
      "mean   1.712243e+09  2.130706e+09       0.017857       0.165179     0.026786   \n",
      "std    4.743745e-02  0.000000e+00       0.132729       0.372173     0.161818   \n",
      "min    1.712243e+09  2.130706e+09       0.000000       0.000000     0.000000   \n",
      "25%    1.712243e+09  2.130706e+09       0.000000       0.000000     0.000000   \n",
      "50%    1.712243e+09  2.130706e+09       0.000000       0.000000     0.000000   \n",
      "75%    1.712243e+09  2.130706e+09       0.000000       0.000000     0.000000   \n",
      "max    1.712243e+09  2.130706e+09       1.000000       1.000000     1.000000   \n",
      "\n",
      "       nullArgument  logicOperator  nreturned       cpuNanos       label  \\\n",
      "count    224.000000     224.000000      224.0     224.000000  224.000000   \n",
      "mean       0.116071       0.017857        0.0   99642.169643    0.464286   \n",
      "std        0.321028       0.132729        0.0   44007.532865    0.499840   \n",
      "min        0.000000       0.000000        0.0   49784.000000    0.000000   \n",
      "25%        0.000000       0.000000        0.0   71093.000000    0.000000   \n",
      "50%        0.000000       0.000000        0.0   88842.000000    0.000000   \n",
      "75%        0.000000       0.000000        0.0  114685.250000    1.000000   \n",
      "max        1.000000       1.000000        0.0  378420.000000    1.000000   \n",
      "\n",
      "       planningTimeMicros  \n",
      "count          224.000000  \n",
      "mean            63.125000  \n",
      "std             46.788164  \n",
      "min             27.000000  \n",
      "25%             41.750000  \n",
      "50%             55.500000  \n",
      "75%             67.000000  \n",
      "max            407.000000  \n",
      "\n",
      "Null Values:\n",
      "t                              0\n",
      "filter_str                     0\n",
      "docUUID                        0\n",
      "denamed                        0\n",
      "FindCollectionTarget           0\n",
      "FindCollectionTargetdeNamed    0\n",
      "ipHash                         0\n",
      "port                           0\n",
      "whereDetected                  0\n",
      "regexDetected                  0\n",
      "emptyFilter                    0\n",
      "nullArgument                   0\n",
      "logicOperator                  0\n",
      "db                             0\n",
      "denamedDb                      0\n",
      "nreturned                      0\n",
      "cpuNanos                       0\n",
      "label                          0\n",
      "planningTimeMicros             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "final_df = merged_df[['t','filter_str','docUUID','denamed','FindCollectionTarget','FindCollectionTargetdeNamed','queryLength','ipHash','port','whereDetected','regexDetected','emptyFilter','nullArgument','logicOperator','db','denamedDb','nreturned','cpuNanos','label','planningTimeMicros']]\n",
    "print(final_df.head())\n",
    "print(\"Shape of the DataFrame:\", final_df.shape)\n",
    "print(\"\\nData Types:\")\n",
    "print(final_df.dtypes)\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(final_df.describe())\n",
    "print(\"\\nNull Values:\")\n",
    "print(final_df.isnull().sum())\n",
    "\n",
    "final_df.to_csv('../Dataset/final.csv', index=False)\n",
    "\n",
    "stats = {\n",
    "    'shape': final_df.shape,\n",
    "    'dtypes': final_df.dtypes.apply(lambda x: x.name).to_dict(),\n",
    "    'descriptive_stats': final_df.describe().to_dict(),\n",
    "    'null_values': final_df.isnull().sum().to_dict()\n",
    "}\n",
    "\n",
    "with open('../Dataset/metadata.json', 'w') as file:\n",
    "    json.dump(stats, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
