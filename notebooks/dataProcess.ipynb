{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from dateutil import parser\n",
    "import json\n",
    "import ipaddress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignoreList = ['.length ']\n",
    "matchPatterns = []\n",
    "def tokenize_filter(filter_dict):\n",
    "    tokens = []\n",
    "    if filter_dict is not None:\n",
    "        filter_str = json.dumps(filter_dict)\n",
    "        tokens = re.findall(r\"\\[\\w']+|\\[.,!?;\\]\", filter_str)\n",
    "    return tokens\n",
    "\n",
    "def replace_alpha_words(text):\n",
    "    if text is None:\n",
    "        return(\"\")\n",
    "    else:\n",
    "        text = re.sub(r\"\\^[(\\w\\d|)\\\\+]+\", 'name', text) \n",
    "        text = re.sub(r\"\\w+\\{\\}\", 'name', text)\n",
    "        text = re.sub(r\"\\^\\w+\",'name',text)\n",
    "        text = re.sub(r\"\\&\\w+\",'name',text)\n",
    "        text = re.sub(r\"&ne\",'name',text)\n",
    "        text = re.sub(r\"test\\{\\}\",'name',text)\n",
    "        text = re.sub(r\"admin\",'name',text)\n",
    "        text = re.sub(r\"benign\",'name',text)\n",
    "        text = re.sub(r\"malicious\",'name',text)\n",
    "        text = re.sub(r\"\\$username\",'name',text)\n",
    "        text = re.sub(r\"\\$password\",'name',text)\n",
    "        text = re.sub(r\"'[\\w ]+'\", '\\'name\\'', text)\n",
    "        text = re.sub(r\"\\{\\}\\|name\", 'name', text)\n",
    "        text = re.sub(r\"\\.\\*\\{\\}\\.\\*\", 'name', text)\n",
    "        text = re.sub(r\"\\{\\}\\.\\*name\\.\\*\", 'name', text)  \n",
    "        text = re.sub(r\"\\^\\{\\}\\$\", 'name', text)\n",
    "        text = re.sub(r\"\\^\\{\\}\", 'name', text)\n",
    "        text = re.sub(r\"\\^name\\$\", 'name', text)\n",
    "        text = re.sub(r\"test\\'name\\'\\{\\}\", 'name', text)\n",
    "        text = re.sub(r'this\\.name',\"this.\",text)\n",
    "        text = text.replace(\"test'name'{}\",\"name\")\n",
    "        text = re.sub(r'name',\"\",text)\n",
    "        text = re.sub(r'name',\"\",text)       \n",
    "        return text\n",
    "    \n",
    "def replace_nums(text):\n",
    "    if text is None:\n",
    "        return(\"\")\n",
    "    else:\n",
    "        regex = r\"\\d+\"\n",
    "        return re.sub(r\"\\d+\", '\\'name\\'', text)\n",
    "\n",
    "def replace_this_var(text):\n",
    "    matched = (re.findall(r\"\\.[\\w]+\",text))\n",
    "    #matchPatterns.append(matched)\n",
    "    for matches in matched:\n",
    "        if str(matches) != '.length':\n",
    "            text = re.sub(matches,\".name\",text)\n",
    "        else:\n",
    "            matchPatterns.append(matches)\n",
    "    return text\n",
    "\n",
    "def replace_this_var_condi(text):\n",
    "    regex = r\"^(?!\\$)\\w+\"\n",
    "    return int(re.sub(r\"\\.[\\w]+[\\.]\",\".name.\",text))\n",
    "\n",
    "def comparisonOperator(text):\n",
    "    pattern = r'\\$(gt|eq|gte|in|lt|lte|ne|nin)'\n",
    "    return 1 if re.search(pattern, text) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'user': '{}', 'password': '{}'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'username': {'$regex': '^{}'}}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'username': {'$ne': '{}'}}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'username': {'$gt': '{}'}}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'user': 'hacker', 'password': {'$ne': ''}}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text  label\n",
       "0             {'user': '{}', 'password': '{}'}      0\n",
       "1              {'username': {'$regex': '^{}'}}      1\n",
       "2                  {'username': {'$ne': '{}'}}      1\n",
       "3                  {'username': {'$gt': '{}'}}      1\n",
       "4  {'user': 'hacker', 'password': {'$ne': ''}}      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelData = pd.read_json(\"../No-SQL_Gen/No-SqlDataset.json\")\n",
    "labelData['text'] = labelData['text'].apply(lambda x: x.replace('\"', \"'\") if isinstance(x, str) else x)\n",
    "labelData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    176371\n",
       "1    112781\n",
       "2     71093\n",
       "3     81173\n",
       "4    141175\n",
       "Name: cpuNanos, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logData = pd.read_json('../Dataset/queryLogs.json')\n",
    "logData.head()\n",
    "logData['t'] = logData['t'].apply(lambda x: parser.parse(x['$date']).timestamp())\n",
    "attr_cols = ['type', 'ns', 'command', 'planSummary', 'planningTimeMicros', 'keysExamined', 'docsExamined', 'nBatches', 'cursorExhausted', 'numYields', 'nreturned', 'queryFramework', 'reslen', 'locks', 'storage', 'cpuNanos', 'remote', 'protocol', 'durationMillis']\n",
    "for col in attr_cols:\n",
    "    logData[col] = logData['attr'].apply(lambda x: x.get(col, None))\n",
    "logData['FindCollectionTarget'] = logData['command'].apply(lambda x: x.get('find', None) if isinstance(x, dict) else \"None\")\n",
    "logData['filter'] = logData['command'].apply(lambda x: x.get('filter', None) if isinstance(x, dict) else None)\n",
    "logData['tokenized_filter'] = logData['filter'].apply(lambda x: tokenize_filter(str(x)) if x is not None else None)\n",
    "logData['docUUID'] = logData['command'].apply(lambda x: x.get('lsid', {}).get('id', {}).get('$uuid', None) if isinstance(x, dict) else None)\n",
    "logData['db'] = logData['command'].apply(lambda x: x.get('$db', None) if isinstance(x, dict) else None)\n",
    "logData['db'] = logData['command'].apply(lambda x: x.get('$db', None) if isinstance(x, dict) else None)\n",
    "logData['filter_str'] = logData['filter'].apply(lambda x: str(x) if x is not None else None)\n",
    "logData['returnDataSize'] = logData['command'].apply(lambda x: x.get('nreturned', None) if isinstance(x, dict) else None)\n",
    "#nreturned\n",
    "logData['cpuNanos'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelData = pd.read_json(\"../No-SQL_Gen/No-SqlDataset.json\")\n",
    "labelData['text'] = labelData['text'].apply(lambda x: x.replace('\"', \"'\") if isinstance(x, str) else x)\n",
    "labelData.head()\n",
    "merged_df = pd.merge(logData[['t','filter_str','remote','FindCollectionTarget','db','docUUID', 'nreturned', 'cpuNanos', 'planningTimeMicros']], labelData[['text', 'label']], how='left', left_on='filter_str', right_on='text')\n",
    "merged_df = merged_df.drop('text',axis=1)\n",
    "merged_df['FindCollectionTargetdeNamed'] = merged_df['FindCollectionTarget'].apply(replace_alpha_words)\n",
    "merged_df['filter_str'] = merged_df['filter_str'].apply(lambda x: x.replace('\"', \"'\") if isinstance(x, str) else x)\n",
    "merged_df['filter_str'] = merged_df['filter_str'].apply(lambda x : str(x))\n",
    "merged_df['queryLength'] = merged_df['filter_str'].apply(lambda x: len(str(x)))\n",
    "merged_df['whereDetected'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"\\$where\", x)) else 0)\n",
    "merged_df['regexDetected'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"\\$(regex)|\\$(elemMatch)\", x)) else 0)\n",
    "merged_df['emptyFilter'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"^\\{\\}$\", x)) else 0)\n",
    "merged_df['nullArgument'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"\\{\\}'\", x)) else 0)\n",
    "merged_df['logicOperator'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"\\$gt|\\$eq|\\$in|\\$nin|\\$ne|[>=<]{2}\", x)) else 0)\n",
    "merged_df['matcherOption'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"\\$option\", x)) else 0)\n",
    "merged_df['MathOperator'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"\\$size\", x)) else 0)\n",
    "merged_df['Size'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"\\$size|this|length\", x)) else 0)\n",
    "merged_df['thisPointer'] = merged_df['filter_str'].apply(lambda x: 1 if bool(re.search(r\"this\", x)) else 0)\n",
    "merged_df['denamed'] = merged_df['filter_str'].apply(replace_alpha_words)\n",
    "merged_df['denamed'] = merged_df['denamed'].apply(replace_this_var)\n",
    "merged_df['denamed'] = merged_df['denamed'].apply(replace_nums)\n",
    "merged_df['denamedDb'] = merged_df['db'].apply(replace_alpha_words)\n",
    "merged_df['ipHash'] = merged_df['remote'].apply(lambda ip: hash(int(ipaddress.IPv4Address(ip.split(':')[0]))))\n",
    "merged_df['port'] = merged_df['remote'].apply(lambda ip: ip.split(':')[1])\n",
    "merged_df = merged_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         filter_str               denamed  queryLength  \\\n",
      "0  {'user': '{}', 'password': '{}'}  {'': '{}', '': '{}'}           32   \n",
      "1  {'user': '{}', 'password': '{}'}  {'': '{}', '': '{}'}           32   \n",
      "2   {'username': {'$regex': '^{}'}}  {'': {'$regex': ''}}           31   \n",
      "3   {'username': {'$regex': '^{}'}}  {'': {'$regex': ''}}           31   \n",
      "4       {'username': {'$ne': '{}'}}   {'': {'$ne': '{}'}}           27   \n",
      "\n",
      "   whereDetected  regexDetected  logicOperator  MathOperator  Size  \\\n",
      "0              0              0              0             0     0   \n",
      "1              0              0              0             0     0   \n",
      "2              0              1              0             0     0   \n",
      "3              0              1              0             0     0   \n",
      "4              0              0              1             0     0   \n",
      "\n",
      "   thisPointer  matcherOption  cpuNanos  planningTimeMicros  label  \n",
      "0            0              0    176371                83.0    0.0  \n",
      "1            0              0    176371                83.0    0.0  \n",
      "2            0              0    112781                71.0    1.0  \n",
      "3            0              0    112781                71.0    1.0  \n",
      "4            0              0     71093                42.0    1.0  \n",
      "Shape of the DataFrame: (224, 13)\n",
      "\n",
      "Data Types:\n",
      "filter_str             object\n",
      "denamed                object\n",
      "queryLength             int64\n",
      "whereDetected           int64\n",
      "regexDetected           int64\n",
      "logicOperator           int64\n",
      "MathOperator            int64\n",
      "Size                    int64\n",
      "thisPointer             int64\n",
      "matcherOption           int64\n",
      "cpuNanos                int64\n",
      "planningTimeMicros    float64\n",
      "label                 float64\n",
      "dtype: object\n",
      "\n",
      "Descriptive Statistics:\n",
      "       queryLength  whereDetected  regexDetected  logicOperator  MathOperator  \\\n",
      "count   224.000000     224.000000     224.000000     224.000000    224.000000   \n",
      "mean     46.776786       0.017857       0.183036       0.370536      0.053571   \n",
      "std      19.571971       0.132729       0.387562       0.484030      0.225674   \n",
      "min       2.000000       0.000000       0.000000       0.000000      0.000000   \n",
      "25%      33.000000       0.000000       0.000000       0.000000      0.000000   \n",
      "50%      43.000000       0.000000       0.000000       0.000000      0.000000   \n",
      "75%      58.000000       0.000000       0.000000       1.000000      0.000000   \n",
      "max     105.000000       1.000000       1.000000       1.000000      1.000000   \n",
      "\n",
      "             Size  thisPointer  matcherOption       cpuNanos  \\\n",
      "count  224.000000   224.000000     224.000000     224.000000   \n",
      "mean     0.071429     0.017857       0.022321   99642.169643   \n",
      "std      0.258116     0.132729       0.148058   44007.532865   \n",
      "min      0.000000     0.000000       0.000000   49784.000000   \n",
      "25%      0.000000     0.000000       0.000000   71093.000000   \n",
      "50%      0.000000     0.000000       0.000000   88842.000000   \n",
      "75%      0.000000     0.000000       0.000000  114685.250000   \n",
      "max      1.000000     1.000000       1.000000  378420.000000   \n",
      "\n",
      "       planningTimeMicros       label  \n",
      "count          224.000000  224.000000  \n",
      "mean            63.125000    0.464286  \n",
      "std             46.788164    0.499840  \n",
      "min             27.000000    0.000000  \n",
      "25%             41.750000    0.000000  \n",
      "50%             55.500000    0.000000  \n",
      "75%             67.000000    1.000000  \n",
      "max            407.000000    1.000000  \n",
      "\n",
      "Null Values:\n",
      "filter_str            0\n",
      "denamed               0\n",
      "queryLength           0\n",
      "whereDetected         0\n",
      "regexDetected         0\n",
      "logicOperator         0\n",
      "MathOperator          0\n",
      "Size                  0\n",
      "thisPointer           0\n",
      "matcherOption         0\n",
      "cpuNanos              0\n",
      "planningTimeMicros    0\n",
      "label                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "final_df = merged_df[['filter_str','denamed','queryLength','whereDetected','regexDetected','logicOperator','MathOperator','Size','thisPointer','matcherOption','cpuNanos','planningTimeMicros','label']]\n",
    "print(final_df.head())\n",
    "print(\"Shape of the DataFrame:\", final_df.shape)\n",
    "print(\"\\nData Types:\")\n",
    "print(final_df.dtypes)\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(final_df.describe())\n",
    "print(\"\\nNull Values:\")\n",
    "print(final_df.isnull().sum())\n",
    "\n",
    "final_df.to_csv('../Dataset/final.csv', index=False)\n",
    "\n",
    "stats = {\n",
    "    'shape': final_df.shape,\n",
    "    'dtypes': final_df.dtypes.apply(lambda x: x.name).to_dict(),\n",
    "    'descriptive_stats': final_df.describe().to_dict(),\n",
    "    'null_values': final_df.isnull().sum().to_dict()\n",
    "}\n",
    "\n",
    "with open('../Dataset/metadata.json', 'w') as file:\n",
    "    json.dump(stats, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
